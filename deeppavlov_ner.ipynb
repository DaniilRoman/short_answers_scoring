{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.3\r\n"
     ]
    }
   ],
   "source": [
    "!python --version # should be 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import configs, build_model\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from natasha import (\n",
    "    DatesExtractor,\n",
    "    MoneyExtractor,\n",
    "    AddrExtractor,\n",
    "    MorphVocab,\n",
    ")\n",
    "\n",
    "from natasha.obj import Money\n",
    "from natasha.obj import Addr\n",
    "from natasha.obj import Date\n",
    "from natasha.obj import AddrPart\n",
    "\n",
    "from natasha import (\n",
    "    NewsNERTagger,\n",
    "    NewsEmbedding,\n",
    ")\n",
    "emb = NewsEmbedding()\n",
    "ner = NewsNERTagger(emb)\n",
    "\n",
    "morph_vocab = MorphVocab()\n",
    "extractors = [\n",
    "    AddrExtractor(morph_vocab),\n",
    "    DatesExtractor(morph_vocab),\n",
    "    MoneyExtractor(morph_vocab)\n",
    "]\n",
    "\n",
    "# !python3 -m deeppavlov install ner_ontonotes_bert_mult"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/droman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/droman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/droman/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/droman/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-18 10:05:04.70 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/droman/.deeppavlov/models/ner_rus_bert/tag.dict]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-18 10:05:19.263 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/droman/.deeppavlov/models/ner_rus_bert/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/droman/.deeppavlov/models/ner_rus_bert/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-18 10:05:23.110 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/droman/.deeppavlov/models/ner_ontonotes_bert_mult/tag.dict]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-18 10:05:42.912 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/droman/.deeppavlov/models/ner_ontonotes_bert_mult/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/droman/.deeppavlov/models/ner_ontonotes_bert_mult/model\n"
     ]
    }
   ],
   "source": [
    "config_path = configs.ner.ner_rus_bert\n",
    "ner = build_model(config_path, download=False)\n",
    "ner_multi = build_model(configs.ner.ner_ontonotes_bert_mult, download=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sentence = 'Директором ОАО \"Страна Чудес\" назначена Алиса'\n",
    "#\n",
    "# # Можно так же список слов\n",
    "# # sentence = ['Директором', 'ОАО', '\"', 'Страна', 'Чудес', '\"', 'назначена', 'Алиса']\n",
    "#\n",
    "# tokens, tags = ner(['Ио́сиф Виссарио́нович Ста́лин — российский революционер, советский политический, государственный, военный и партийный деятель. С 21 января 1924 по 5 марта 1953 — руководитель СССР. Маршал Советского Союза, Генералиссимус Советского Союза.'])\n",
    "# for tok, tag in zip(tokens[0], tags[0]):\n",
    "#     print(f'{tok}\\t{tag}')\n",
    "#\n",
    "# example_str = ['Ио́сиф Виссарио́нович Ста́лин — российский революционер, советский политический, государственный, военный и партийный деятель. С 21 января 1924 по 5 марта 1953 — руководитель СССР. Маршал Советского Союза, Генералиссимус Советского Союза.']\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def print_tokens(tokens, tags):\n",
    "    for tok, tag in zip(tokens, tags):\n",
    "        print(f'{tok}\\t{tag}')\n",
    "\n",
    "def filter_after_ner(tokens, tags):\n",
    "    stop_words = ['́']\n",
    "    excluded_indexes = []\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] in stop_words:\n",
    "            excluded_indexes.append(i)\n",
    "    def filter_by_index(l):\n",
    "        return [l[i] for i in range(len(l)) if i not in excluded_indexes]\n",
    "    return filter_by_index(tokens), filter_by_index(tags)\n",
    "\n",
    "def get_deeppavlov_entities(tokens, tags):\n",
    "    entities = []\n",
    "    entity = ''\n",
    "    for tok, tag in zip(tokens, tags):\n",
    "        if tag == 'O' and entity != '':\n",
    "            entities.append(entity)\n",
    "            entity = ''\n",
    "        if 'B-' in tag:\n",
    "            entity = tok\n",
    "        if 'I-' in tag:\n",
    "            entity += ' ' + tok\n",
    "    return entities\n",
    "\n",
    "def nearest(sent1, sent2):\n",
    "    for i in sent2:\n",
    "        distance = fuzz.token_sort_ratio(sent1.lower(), i.lower()) #nltk.edit_distance(sent1, i)\n",
    "        if distance >= 80:\n",
    "            return True\n",
    "        # if (distance/len(sent1)) * 100 <= 30:\n",
    "        #     return True\n",
    "    return False\n",
    "\n",
    "def get_percent(part_entities, full_entities):\n",
    "    max_count = len(full_entities)\n",
    "    real_count = 0\n",
    "    for i in part_entities:\n",
    "        if nearest(i, full_entities):\n",
    "            real_count += 1\n",
    "    if max_count == 0:\n",
    "        return 0.\n",
    "    return real_count / max_count\n",
    "\n",
    "def get_entities_from_natasha_extractors(text):\n",
    "    spans = []\n",
    "    entities = []\n",
    "    for extractor in extractors:\n",
    "        matches = extractor(text)\n",
    "        spans.extend(_ for _ in matches)\n",
    "    for span in spans:\n",
    "        fact = span.fact\n",
    "        if type(fact) is Money:\n",
    "            entities.append(str(fact.amount))\n",
    "        else:\n",
    "            if type(fact) is Date:\n",
    "                entities.append(str(fact.year) + \" \" + str(fact.month) + \" \" + str(fact.day))\n",
    "            else:\n",
    "                if type(fact) is AddrPart and fact.type is not None:\n",
    "                    entities.append(str(fact.value))\n",
    "    return entities\n",
    "\n",
    "def get_natasha_ner_entities(text):\n",
    "    markup = ner(text)\n",
    "    spans = markup.spans\n",
    "    entities = []\n",
    "    for span in spans:\n",
    "        entities.append(text[span.start: span.stop])\n",
    "    return entities\n",
    "\n",
    "def get_natasha_entities(text):\n",
    "    return list(set(get_entities_from_natasha_extractors(text) + get_natasha_ner_entities(text)))\n",
    "\n",
    "def get_overlap_entities_percent(sent1, sent2, model_ents_funcs):\n",
    "    entities1 = set()\n",
    "    entities2 = set()\n",
    "\n",
    "    for model in model_ents_funcs:\n",
    "        entities1.update(model(sent1))\n",
    "        entities2.update(model(sent2))\n",
    "\n",
    "    return get_percent(entities1, entities2)\n",
    "\n",
    "def get_deeppavlov_ents(sent):\n",
    "    tokens1, tags1 = ner_multi(sent)\n",
    "    tokens1, tags1 = tokens1[0], tags1[0]\n",
    "\n",
    "    filtered_tokens1, filtered_tags1 = filter_after_ner(tokens1, tags1)\n",
    "\n",
    "    return get_deeppavlov_entities(filtered_tokens1, filtered_tags1)\n",
    "\n",
    "def get_ner_overlap_feature(data):\n",
    "    original = data[\"original\"].tolist()\n",
    "    targets = data[\"scored_text\"].tolist()\n",
    "    feature_values = []\n",
    "    ner_ents_extractors = [get_deeppavlov_ents, get_natasha_entities]\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(original))):\n",
    "        origin = original[i]\n",
    "        target = targets[i]\n",
    "        try:\n",
    "            if target == \" \" or target == \"\" or target is None:\n",
    "                feature_values.append(0.)\n",
    "                continue\n",
    "            feature_value = get_overlap_entities_percent([target], [origin], ner_ents_extractors)\n",
    "            feature_values.append(feature_value)\n",
    "        except:\n",
    "            feature_values.append(0.)\n",
    "            print(\"index: \", i)\n",
    "            print(\"raget text: \", target)\n",
    "            print(\"origin text: \", origin)\n",
    "    return feature_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}