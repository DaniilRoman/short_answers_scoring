{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.3\r\n"
     ]
    }
   ],
   "source": [
    "!python --version # should be 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "[nltk_data] Downloading package punkt to /home/droman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/droman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/droman/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/droman/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-18 21:31:31.409 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/droman/.deeppavlov/models/ner_ontonotes_bert_mult/tag.dict]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-18 21:31:49.831 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/droman/.deeppavlov/models/ner_ontonotes_bert_mult/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/droman/.deeppavlov/models/ner_ontonotes_bert_mult/model\n"
     ]
    }
   ],
   "source": [
    "import sys, traceback\n",
    "from deeppavlov import configs, build_model\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from natasha import (\n",
    "    DatesExtractor,\n",
    "    MoneyExtractor,\n",
    "    AddrExtractor,\n",
    "    MorphVocab,\n",
    ")\n",
    "\n",
    "from natasha.obj import Money\n",
    "from natasha.obj import Addr\n",
    "from natasha.obj import Date\n",
    "from natasha.obj import AddrPart\n",
    "\n",
    "from natasha import (\n",
    "    NewsNERTagger,\n",
    "    NewsEmbedding,\n",
    ")\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir=Path(\"/home/droman/Documents/diploma/deeppavlov_ner_3.6/data/ner_custom_model\")\n",
    "spacy_custom_ner = spacy.load(output_dir)\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "ner = NewsNERTagger(emb)\n",
    "\n",
    "morph_vocab = MorphVocab()\n",
    "extractors = [\n",
    "    AddrExtractor(morph_vocab),\n",
    "    DatesExtractor(morph_vocab),\n",
    "    MoneyExtractor(morph_vocab)\n",
    "]\n",
    "\n",
    "# !python3 -m deeppavlov install ner_ontonotes_bert_mult\n",
    "\n",
    "# config_path = configs.ner.ner_rus_bert\n",
    "# ner = build_model(config_path)\n",
    "ner_multi = build_model(configs.ner.ner_ontonotes_bert_mult, download=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def print_tokens(tokens, tags):\n",
    "    for tok, tag in zip(tokens, tags):\n",
    "        print(f'{tok}\\t{tag}')\n",
    "\n",
    "def filter_after_ner(tokens, tags):\n",
    "    stop_words = ['́']\n",
    "    excluded_indexes = []\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] in stop_words:\n",
    "            excluded_indexes.append(i)\n",
    "    def filter_by_index(l):\n",
    "        return [l[i] for i in range(len(l)) if i not in excluded_indexes]\n",
    "    return filter_by_index(tokens), filter_by_index(tags)\n",
    "\n",
    "def get_deeppavlov_entities(tokens, tags):\n",
    "    entities = []\n",
    "    entity = ''\n",
    "    for tok, tag in zip(tokens, tags):\n",
    "        if tag == 'O' and entity != '':\n",
    "            entities.append(entity)\n",
    "            entity = ''\n",
    "        if 'B-' in tag:\n",
    "            entity = tok\n",
    "        if 'I-' in tag:\n",
    "            entity += ' ' + tok\n",
    "    return entities\n",
    "\n",
    "def nearest(sent1, sent2):\n",
    "    for i in sent2:\n",
    "        distance = fuzz.token_sort_ratio(sent1.lower(), i.lower()) #nltk.edit_distance(sent1, i)\n",
    "        if distance >= 80:\n",
    "            return True\n",
    "        # if (distance/len(sent1)) * 100 <= 30:\n",
    "        #     return True\n",
    "    return False\n",
    "\n",
    "def get_percent(part_entities, full_entities):\n",
    "    max_count = len(full_entities)\n",
    "    real_count = 0\n",
    "    for i in part_entities:\n",
    "        if nearest(i, full_entities):\n",
    "            real_count += 1\n",
    "    if max_count == 0:\n",
    "        return 0.\n",
    "    return real_count / max_count\n",
    "\n",
    "def get_entities_from_natasha_extractors(text):\n",
    "    if type(text) is list:\n",
    "        text = text[0]\n",
    "    spans = []\n",
    "    entities = []\n",
    "    for extractor in extractors:\n",
    "        matches = extractor(text)\n",
    "        if matches is not None:\n",
    "            try:\n",
    "                spans.extend(_ for _ in matches)\n",
    "            except Exception:\n",
    "                print(\"NATASHA MATCHES:\")\n",
    "                print(text)\n",
    "                print(list(matches))\n",
    "                print(\"============================\")\n",
    "    for span in spans:\n",
    "        fact = span.fact\n",
    "        if type(fact) is Money:\n",
    "            entities.append(str(fact.amount))\n",
    "        else:\n",
    "            if type(fact) is Date:\n",
    "                entities.append(str(fact.year) + \" \" + str(fact.month) + \" \" + str(fact.day))\n",
    "            else:\n",
    "                if type(fact) is AddrPart and fact.type is not None:\n",
    "                    entities.append(str(fact.value))\n",
    "    return entities\n",
    "\n",
    "def get_natasha_ner_entities(text):\n",
    "    if type(text) is list:\n",
    "        text = text[0]\n",
    "    entities = []\n",
    "    try:\n",
    "        markup = ner(text)\n",
    "        spans = markup.spans\n",
    "        for span in spans:\n",
    "            entities.append(text[span.start: span.stop])\n",
    "    except Exception:\n",
    "        print(\"Exception in user code:\")\n",
    "        print(text)\n",
    "        print(\"=\"*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print(\"=\"*60)\n",
    "\n",
    "    return entities\n",
    "\n",
    "def get_natasha_entities(text):\n",
    "    return list(set(get_entities_from_natasha_extractors(text) + get_natasha_ner_entities(text)))\n",
    "\n",
    "def get_overlap_entities_percent(sent1, sent2, model_ents_funcs):\n",
    "    entities1 = set()\n",
    "    entities2 = set()\n",
    "\n",
    "    for model in model_ents_funcs:\n",
    "        entities1.update(model(sent1))\n",
    "        entities2.update(model(sent2))\n",
    "\n",
    "    return get_percent(entities1, entities2)\n",
    "\n",
    "def get_deeppavlov_ents(sent):\n",
    "    tokens1, tags1 = ner_multi(sent)\n",
    "    tokens1, tags1 = tokens1[0], tags1[0]\n",
    "\n",
    "    filtered_tokens1, filtered_tags1 = filter_after_ner(tokens1, tags1)\n",
    "\n",
    "    return get_deeppavlov_entities(filtered_tokens1, filtered_tags1)\n",
    "\n",
    "def get_spacy_custom_ents(sent):\n",
    "    if type(sent) is list:\n",
    "        sent = sent[0]\n",
    "    return spacy_custom_ner(sent).entsv\n",
    "\n",
    "def get_ner_overlap_feature(data):\n",
    "    # ner_ents_extractors = [get_deeppavlov_ents, get_natasha_entities, get_spacy_ents]\n",
    "    ner_ents_extractors = [get_deeppavlov_ents, get_natasha_entities]\n",
    "\n",
    "    return get_abstract_ner_overlap_feature(data, ner_ents_extractors)\n",
    "\n",
    "def get_ner_custom_overlap_feature(data):\n",
    "    ner_ents_extractors = [get_spacy_custom_ents]\n",
    "\n",
    "    return get_abstract_ner_overlap_feature(data, ner_ents_extractors)\n",
    "\n",
    "def get_abstract_ner_overlap_feature(data, ner_ents_extractors):\n",
    "    original = data[\"original\"].tolist()\n",
    "    targets = data[\"scored_text\"].tolist()\n",
    "    feature_values = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(original))):\n",
    "        origin = original[i]\n",
    "        target = targets[i]\n",
    "        try:\n",
    "            if target == \" \" or target == \"\" or target is None:\n",
    "                feature_values.append(0.)\n",
    "                continue\n",
    "            feature_value = get_overlap_entities_percent([target], [origin], ner_ents_extractors)\n",
    "            feature_values.append(feature_value)\n",
    "        except Exception:\n",
    "            print(\"Exception in user code:\")\n",
    "            print(\"-\"*60)\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "            print(\"-\"*60)\n",
    "            feature_values.append(0.)\n",
    "            print(\"index: \", i)\n",
    "            print(\"raget text: \", target)\n",
    "            print(\"origin text: \", origin)\n",
    "    return feature_values\n",
    "\n",
    "def run_entities_overlap(input=\"/home/droman/Documents/diploma/spacy/data/result.csv\",\n",
    "                         input_for_custom_ner=\"/home/droman/Documents/diploma/deeppavlov_ner_3.6/data/data_with_preprocess.csv\",\n",
    "                         output=\"./data/ner_overlap_result.csv\"):\n",
    "    data = pd.read_csv(input, index_col=False)\n",
    "    ner_overlap_feature = get_ner_overlap_feature(data)\n",
    "    data[\"ner_overlap\"] = ner_overlap_feature\n",
    "\n",
    "    data_for_custom_ner = pd.read_csv(input_for_custom_ner, index_col=False)\n",
    "    assert len(data) == len(data_for_custom_ner)\n",
    "    ner_custom_overlap_feature = get_ner_custom_overlap_feature(data_for_custom_ner)\n",
    "    data[\"ner_custom_overlap\"] = ner_custom_overlap_feature\n",
    "    data.to_csv(output, index=False)\n",
    "    print(pd.read_csv(output).head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [02:07<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           original  \\\n",
      "0           0  великий княжество владимирский 1157год      — ...   \n",
      "1           1  новгородский республика      —      севернорус...   \n",
      "2           2  великий княжество литовский     —      восточн...   \n",
      "3           3  великий княжество московский     —      средне...   \n",
      "4           4  олег      —      князь новгородский 879 год ве...   \n",
      "\n",
      "                                         scored_text  distance  score  \\\n",
      "0  середина xiii век сюзеренитет великий князь вл...  0.923924      5   \n",
      "1  находиться 1245 год сюзеренитет великий князь ...  0.908120      5   \n",
      "2  1385 год находиться личный уния королевство по...  0.861883      5   \n",
      "3  возвышение москва укрепление авторитет русь сп...  0.901416      5   \n",
      "4  получать власть новгородский земля смерть рюри...  0.916509      5   \n",
      "\n",
      "   ner_overlap  \n",
      "0     1.000000  \n",
      "1     0.909091  \n",
      "2     0.777778  \n",
      "3     0.625000  \n",
      "4     1.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_entities_overlap(input=\"/home/droman/Documents/diploma/deeppavlov_ner_3.6/data/data_with_preprocess.csv\",\n",
    "                     input_for_custom_ner=\"/home/droman/Documents/diploma/deeppavlov_ner_3.6/data/data_with_preprocess.csv\",\n",
    "                     output=\"./data/ner_overlap_result_with_preprocess.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: spacy\r\n",
      "Version: 2.3.5\r\n",
      "Summary: Industrial-strength Natural Language Processing (NLP) in Python\r\n",
      "Home-page: https://spacy.io\r\n",
      "Author: Explosion\r\n",
      "Author-email: contact@explosion.ai\r\n",
      "License: MIT\r\n",
      "Location: /home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages\r\n",
      "Requires: catalogue, setuptools, tqdm, wasabi, numpy, blis, plac, thinc, preshed, requests, srsly, cymem, murmurhash\r\n",
      "Required-by: pyresparser\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install spacy==2.3.5\n",
    "!python -m pip show spacy # should be 2.3.5\n",
    "# !pip install nltk\n",
    "# !pip install pyresparser\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# local: bert_score, USE\n",
    "# colab: fasttext"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}