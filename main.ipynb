{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.3\r\n"
     ]
    }
   ],
   "source": [
    "!python --version # should be 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/droman/Documents/diploma/deeppavlov_ner_3.6/venv/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import configs, build_model\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from natasha import (\n",
    "    DatesExtractor,\n",
    "    MoneyExtractor,\n",
    "    AddrExtractor,\n",
    "    MorphVocab,\n",
    ")\n",
    "\n",
    "from natasha.obj import Money\n",
    "from natasha.obj import Addr\n",
    "from natasha.obj import Date\n",
    "from natasha.obj import AddrPart\n",
    "\n",
    "from natasha import (\n",
    "    NewsNERTagger,\n",
    "    NewsEmbedding,\n",
    ")\n",
    "emb = NewsEmbedding()\n",
    "ner = NewsNERTagger(emb)\n",
    "\n",
    "morph_vocab = MorphVocab()\n",
    "extractors = [\n",
    "    AddrExtractor(morph_vocab),\n",
    "    DatesExtractor(morph_vocab),\n",
    "    MoneyExtractor(morph_vocab)\n",
    "]\n",
    "\n",
    "# !python3 -m deeppavlov install ner_ontonotes_bert_mult\n",
    "\n",
    "# config_path = configs.ner.ner_rus_bert\n",
    "# ner = build_model(config_path)\n",
    "ner_multi = build_model(configs.ner.ner_ontonotes_bert_mult, download=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def print_tokens(tokens, tags):\n",
    "    for tok, tag in zip(tokens, tags):\n",
    "        print(f'{tok}\\t{tag}')\n",
    "\n",
    "def filter_after_ner(tokens, tags):\n",
    "    stop_words = ['́']\n",
    "    excluded_indexes = []\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] in stop_words:\n",
    "            excluded_indexes.append(i)\n",
    "    def filter_by_index(l):\n",
    "        return [l[i] for i in range(len(l)) if i not in excluded_indexes]\n",
    "    return filter_by_index(tokens), filter_by_index(tags)\n",
    "\n",
    "def get_deeppavlov_entities(tokens, tags):\n",
    "    entities = []\n",
    "    entity = ''\n",
    "    for tok, tag in zip(tokens, tags):\n",
    "        if tag == 'O' and entity != '':\n",
    "            entities.append(entity)\n",
    "            entity = ''\n",
    "        if 'B-' in tag:\n",
    "            entity = tok\n",
    "        if 'I-' in tag:\n",
    "            entity += ' ' + tok\n",
    "    return entities\n",
    "\n",
    "def nearest(sent1, sent2):\n",
    "    for i in sent2:\n",
    "        distance = fuzz.token_sort_ratio(sent1.lower(), i.lower()) #nltk.edit_distance(sent1, i)\n",
    "        if distance >= 80:\n",
    "            return True\n",
    "        # if (distance/len(sent1)) * 100 <= 30:\n",
    "        #     return True\n",
    "    return False\n",
    "\n",
    "def get_percent(part_entities, full_entities):\n",
    "    max_count = len(full_entities)\n",
    "    real_count = 0\n",
    "    for i in part_entities:\n",
    "        if nearest(i, full_entities):\n",
    "            real_count += 1\n",
    "    if max_count == 0:\n",
    "        return 0.\n",
    "    return real_count / max_count\n",
    "\n",
    "def get_entities_from_natasha_extractors(text):\n",
    "    spans = []\n",
    "    entities = []\n",
    "    for extractor in extractors:\n",
    "        matches = extractor(text)\n",
    "        spans.extend(_ for _ in matches)\n",
    "    for span in spans:\n",
    "        fact = span.fact\n",
    "        if type(fact) is Money:\n",
    "            entities.append(str(fact.amount))\n",
    "        else:\n",
    "            if type(fact) is Date:\n",
    "                entities.append(str(fact.year) + \" \" + str(fact.month) + \" \" + str(fact.day))\n",
    "            else:\n",
    "                if type(fact) is AddrPart and fact.type is not None:\n",
    "                    entities.append(str(fact.value))\n",
    "    return entities\n",
    "\n",
    "def get_natasha_ner_entities(text):\n",
    "    markup = ner(text)\n",
    "    spans = markup.spans\n",
    "    entities = []\n",
    "    for span in spans:\n",
    "        entities.append(text[span.start: span.stop])\n",
    "    return entities\n",
    "\n",
    "def get_natasha_entities(text):\n",
    "    return list(set(get_entities_from_natasha_extractors(text) + get_natasha_ner_entities(text)))\n",
    "\n",
    "def get_overlap_entities_percent(sent1, sent2, model_ents_funcs):\n",
    "    entities1 = set()\n",
    "    entities2 = set()\n",
    "\n",
    "    for model in model_ents_funcs:\n",
    "        entities1.update(model(sent1))\n",
    "        entities2.update(model(sent2))\n",
    "\n",
    "    return get_percent(entities1, entities2)\n",
    "\n",
    "def get_deeppavlov_ents(sent):\n",
    "    tokens1, tags1 = ner_multi(sent)\n",
    "    tokens1, tags1 = tokens1[0], tags1[0]\n",
    "\n",
    "    filtered_tokens1, filtered_tags1 = filter_after_ner(tokens1, tags1)\n",
    "\n",
    "    return get_deeppavlov_entities(filtered_tokens1, filtered_tags1)\n",
    "\n",
    "def get_ner_overlap_feature(data):\n",
    "    original = data[\"original\"].tolist()\n",
    "    targets = data[\"scored_text\"].tolist()\n",
    "    feature_values = []\n",
    "    ner_ents_extractors = [get_deeppavlov_ents, get_natasha_entities]\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(original))):\n",
    "        origin = original[i]\n",
    "        target = targets[i]\n",
    "        try:\n",
    "            if target == \" \" or target == \"\" or target is None:\n",
    "                feature_values.append(0.)\n",
    "                continue\n",
    "            feature_value = get_overlap_entities_percent([target], [origin], ner_ents_extractors)\n",
    "            feature_values.append(feature_value)\n",
    "        except:\n",
    "            feature_values.append(0.)\n",
    "            print(\"index: \", i)\n",
    "            print(\"raget text: \", target)\n",
    "            print(\"origin text: \", origin)\n",
    "    return feature_values\n",
    "\n",
    "def run_entities_overlap(input=\"/home/droman/Documents/diploma/spacy/data/result.csv\",\n",
    "                         output=\"./data/ner_overlap_result.csv\"):\n",
    "    data = pd.read_csv(input, index_col=False),\n",
    "    ner_overlap_feature = get_ner_overlap_feature(data),\n",
    "    data[\"ner_overlap\"] = ner_overlap_feature,\n",
    "    data.to_csv(output, index=False),\n",
    "    print(pd.read_csv(output).head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_entities_overlap(input=\"/home/droman/Documents/diploma/spacy/data/result.csv\",\n",
    "                     output=\"./data/ner_overlap_result_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}